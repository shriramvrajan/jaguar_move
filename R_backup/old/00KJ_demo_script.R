## TEMPLATE FOR RUNNING THE SUPERCOMPUTER

# clean up
rm(list = ls())
graphics.off()

# Whether or not to run the script using the supercomputer
supercomputer <- F
# cell number will be row number

## Setting up, based on if we're using the supercomputer or not
# Your output MUST include the "nm" argument,
# otherwise the supercomputer will not know what to get back
if (supercomputer) {
  args <- commandArgs(trailingOnly = TRUE)
  nm <- args[1]
  thread <- args[2]
  control_path <- system("cat sc_full_path", intern = TRUE)

  i <- as.numeric(system(paste("echo `ssh snowi '~/get_rep 1", nm,
                                 thread, control_path, "'`", sep = " "),
                                 intern = TRUE))
  errorlog <- file(paste("errorlog_", nm, "_", i, ".txt", sep = ""),
                         open = "at")
  sink(errorlog, type = "message", append = T)

  pin <- "./data/"
} else {
  i <- 1 # We start from 1 in this case
  nm <- "KJ" # This should match the "nm" from the launch.sh script

  pin <- "./"
}

nlabel <- i

### LIBRARIES ####
# Read in libraries here

library(raster)
library(geosphere)
library(sp)


### FUNCTIONS ####

mk_nbhd <- function(i, sz) {
  mat <- matrix(0, nrow = length(i), ncol = (2 * sz + 1) * (2 * sz + 1))
  tmp <- t(rep(-sz:sz, each = 2 * sz + 1))
  tmp1 <- t(rep(-sz:sz, 2 * sz + 1))
  for (j in 1:length(tmp))
  {
    mat[, j] <- cellFromRowCol(brazil_ras, brdf$row[i] + tmp[j],
                               brdf$col[i] + tmp1[j])
  }
  return(mat)
}

LL_fun <- function(par) { # add nbhd in the function
  # 	print(Sys.time())
  utility <- exp(par[1] * env[, 1] + par[2] * env[, 2] + par[3] * env[, 3] +
                 par[4] * env[, 4] + par[5] * env[, 5] + par[6] * env[, 6])
  probability <- matrix(utility[nbhd], nrow = nrow(nbhd), ncol = ncol(nbhd))
  # nrow=nrow(mini nbhd)*Nobs
  probability <- probability / rowSums(probability, na.rm = T)
  # normalizes properly
  current <- array(0, dim = c(step_range, Nobs, steps))
  current[center, , 1] <- 1
  for (j in 1:(steps - 1)) {
    # takes srcNbhd Nobs matrix, and applies it to each destn using probability
    # yields a srcNbhd,Nobs,dstNbhd dimension matrix
    # then want to sum across all srcNbhd that enter a dstNbhd, for a given Nobs
    # colSums gives back same as apply(a,3,colSums) (not sure why, but it does)
    # i.e., for each destination location, sum across all sources.
    # the new row becomes each obs, thus must transpose
    # the summed input into destination becomes the new sources
    tmp <- as.vector(current[, , j]) * probability[]
    # basically want to do tmp1=tmp[to_dest]
    dest[] <- tmp[as.vector(to_dest)]
    current[, , j + 1] <- rowSums(dest, na.rm = T)
  }
  # current has everything - but need to know where the next obs was (row) for
  # each column, and will sum across each time steps
  temp <- matrix(0, nrow = steps, ncol = Nobs)
  for (i in 1:Nobs) {
    temp[, i] <- current[obs[i], i, ] # returns back the probability for the row
    # associated with the next observation location, for that observation i,
    # across all time steps
  }
  log_likelihood <- rowSums(log(temp), na.rm = T)
  return(-max(log_likelihood))
}



# Iterates based on supercomputer (or not)
iterate <- function(i, supercomputer) {
  # get next iteration number
  if (supercomputer) {
    i <- as.numeric(system(
      paste("echo `ssh snowi '~/get_rep 0", nm, thread, control_path, 
            "'`", sep = " "),
      intern = TRUE
    ))
    # wait 5 seconds to allow server to recover
    Sys.sleep(5)
    return(i)
  } else {
    return(i + 1)
  }
}

### DATA ####
# Read in the appropriate data here
# e.g. temp = readRDS(paste0(pin, "datafile.rds"))
brazil_ras <- stack("data/brazil_ras_4.grd")
load("data/brazil.RData") # brdf
jag_move <- readRDS("data/jag_data.rds")
jag_id <- readRDS("data/jag_list.rds")
print("Loaded data")




### BODY ####
# Number of iterations (based on data)
niter <- length(jag_id)
# i = -99 is an error code generated by the supercomputer, will end the script
# while(i <= niter && i != -99) {
i <- 1
# Output file name: should be appropriately named
fname <- paste0("data/output/jag par", jag_id[i], "-", nm, ".rds")
fname2 <- paste0("data/output/null_likelihood", "-", jag_id[i], "-", nm, ".rds")
fname3 <- paste0("data/output/likelihood", "-", jag_id[i], "-", nm, ".rds")

## INSERT CODE HERE ##
neigh <- mk_nbhd(1:nrow(brdf), 1) 
# this says it goes only 1 point away - so probability of moving to 
# a neighboring cellFromRowCol. This can be used for all of brazil
jag_i_latlong <- as.matrix(jag_move[which(jag_move$ID == jag_id[i]), 3:4]) 
# where the iteration comes in
jag <- cellFromXY(brazil_ras, jag_i_latlong)
#  dist=vector(length=nrow(jag_i_latlong)-1)
dist <- (jag_i_latlong[-nrow(jag_i_latlong), ] - jag_i_latlong[-1, ]) / xres(brazil_ras)
dist <- (rowSums(dist^2))^.5

max_dist <- max(dist) # /1000
size_out <- ceiling(max_dist * 2)
nbhd_index <- mk_nbhd(jag, size_out) 
# this needs to be kept as it contains all points in the original matrix
# the entire neighborhood is now neigh[nbhd[1,],] for the first observation
# create the neighbors within each neighborhood
tmp <- lapply(1:nrow(nbhd_index), function(b) {
  # named vector? need to make sure going to right set of observations too
  # i tells us what row, and therefore what starting point we are in.
  # nbhd[i] - tells us the row, within i
  rn <- 1:ncol(nbhd_index) + (b - 1) * ncol(nbhd_index)
  names(rn) <- nbhd_index[b, ] # index names for i
  tmp <- matrix(rn[as.character(neigh[nbhd_index[b, ], ])], nrow = length(rn), ncol = ncol(neigh))
  return(tmp)
})
nbhd <- do.call(rbind, tmp) # this creates the useable neighborhood matrix, with unique combos of cells and row numbers
nbhd_index <- as.vector(t(nbhd_index)) 
# this allows linkage of row numbers from nbhd2 to the original cells in brazil
to_dest <- tapply(1:length(nbhd), nbhd, function(x) {
  print(x)
  a <- c(x, rep(NA, ncol(nbhd) - length(x))) 
  # make everything the same size, and also include every source that has enters
  return(a)
}) # return which elements go into that dest. keep # of neighbors constant, adding NA where needed
to_dest <- t(matrix(unlist(to_dest), nrow = ncol(nbhd), ncol = nrow(nbhd)))
# dest=matrix(0,nrow=nrow(nbhd),ncol=ncol(nbhd))
dest <- matrix(0, nrow = nrow(nbhd), ncol = ncol(nbhd))
env <- brdf[nbhd_index, 1:6]
env <- sweep(env, 2, colMeans(env), "-")
env <- sweep(env, 2, apply(env, 2, sd), "/")

row.names(env) <- 1:length(nbhd_index) # same indexing as nv
index_mat <- matrix(data = 1:length(nbhd_index), nrow = (nrow(nbhd) / length(jag)), ncol = length(jag))
obs <- vector(length = ncol(index_mat) - 1)
for (y in 1:(ncol(index_mat) - 1)) {
  print(paste(y, "for loop"))
  test <- which(nbhd_index == jag[y + 1])
  num <- which(index_mat[1, y] < test & test < index_mat[nrow(index_mat), y])
  # print(which(index_mat[,y]==test[num]))
  obs[y] <- which(index_mat[, y] == test[num])
}
step_range <- nrow(nbhd) / length(jag)
Nobs <- length(jag)
steps <- 25
center <- step_range / 2 + 0.5
zero <- c(0, 0, 0, 0)
null_likelihood <- LL_fun(zero) # computing null likelihood for deviance

param <- rnorm(6)
print("Running optim...")
temp.out <- optim(param, LL_fun)

# err <- T
# ntry <- 1 # try 20 times
# print(Sys.time())
# while (err && ntry <= 1) {
#   print("final while loop")
#   ntry <- ntry + 1
#   param <- rnorm(6)
#   temp.out <- tryCatch(optim(param, LL_fun), error = function(e) {
#     NA
#   })
#   if (all(is.na(temp.out))) {
#     err <- T
#   } else {
#     # we're done
#     err <- F
#   }
# }
# print(Sys.time())
print("Running LL_fun...")
likelihood <- LL_fun(temp.out[[1]])







# # Save output
# if (!err) {
#   # Save output
#   saveRDS(temp.out, file = fname)
# }
# if (!err) {
#   saveRDS(likelihood, file = fname3)
# }
# saveRDS(null_likelihood, file = fname2)

# #  i = iterate(i, supercomputer)

# cat("\t\tEnd:\t", format(Sys.time(), "%X"), "\n")
# # }
